{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hDqm7L-1yiMX"
      },
      "source": [
        "# Importing Data Using Pandas\n",
        "\n",
        "## Introduction\n",
        "\n",
        "Pandas is a popular library for efficiently wrangling data. It is particularly optimized to work with two-dimensional tabular data that is organized in rows and columns. In this lesson, you will learn how to import tabular data as a Pandas DataFrame object, how to access and manipulate the data in DataFrame objects, and how to export DataFrames to some common file formats.\n",
        "\n",
        "For more information on Pandas, refer to https://pandas.pydata.org/pandas-docs/stable/ .\n",
        "\n",
        "## Objectives\n",
        "\n",
        "You will be able to:  \n",
        "\n",
        "- Use pandas to import data from a CSV and and an Excel spreadsheet\n",
        "- Use pandas to export a DataFrame to a file\n",
        "\n",
        "## Loading Pandas\n",
        "\n",
        "When importing Pandas, it is standard to import it under the alias `pd`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "CKy20pJ6yiMb"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V0Gi5o5ByiMc"
      },
      "source": [
        "## Importing Data\n",
        "\n",
        "There are a few main functions for importing data into a Pandas DataFrame including:\n",
        "\n",
        "* `pd.read_csv()`\n",
        "* `pd.read_excel()`\n",
        "* `pd.read_json()`\n",
        "* `pd.DataFrame.from_dict()`\n",
        "\n",
        "Most of these functions are fairly straightforward; you use `read_csv()` for csv files, `read_excel()` for excel files (both new and old `.xlx` and `.xlsx` formats), and `read_json()` for json files. That said, there are a few nuances you should know about. The first is that the `read_csv()` format can be used for any plain-text delimited file. This may include (but is not limited to) pipe (|) delimited files (`.psv`) and tab separated files (`.tsv`).\n",
        "\n",
        "Let's look at an example by investigating a file, `'bp.txt'`, stored in the `Data` folder."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Update the file path to the correct location\n",
        "# Consider using a relative path if the file is in the same directory as your notebook\n",
        "# file_path = \"C:\\\\Users\\\\USER\\\\Downloads\\\\pandas_data\\\\Data\\\\bp.txt\"  # Original, problematic path\n",
        "file_path = 'Data/bp.txt'  # Example using a relative path, assuming the file is in a subfolder named 'Data'\n",
        "\n",
        "df = pd.read_csv(file_path, delimiter='\\t')"
      ],
      "metadata": {
        "id": "s4RxFIfF5Xax"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "UOZUCVLwyiMd",
        "outputId": "dfca8a94-da0a-4f0d-d5f6-71c94d36a388",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'Data/bp.txt'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-84160c461692>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Import 'bp.txt' file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Data/bp.txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'\\t'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Data/bp.txt'"
          ]
        }
      ],
      "source": [
        "# Import 'bp.txt' file\n",
        "df = pd.read_csv('Data/bp.txt', delimiter='\\t')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2yfaSdEsyiMd"
      },
      "source": [
        "We've now loaded the data from a file into a DataFrame. To investigate the DataFrame, we can use a method called `.head(n)` or `.tail(n)`, which will respectively return first and last __n__ items in the DataFrame."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e0LK33aJyiMe"
      },
      "outputs": [],
      "source": [
        "# Look at the first 3 rows\n",
        "df.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dQgiF_0TyiMf"
      },
      "outputs": [],
      "source": [
        "# Look at the last 4 rows\n",
        "df.tail(4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n8gF5R-7yiMf"
      },
      "source": [
        "This example shows that the data was tab delimited (`\\t`), so an appropriate file extension could have also been `.tsv`. Once we've loaded the dataset, we can export it to any format we would like with the related methods:\n",
        "\n",
        "* `df.to_csv()`\n",
        "* `df.to_excel()`\n",
        "* `df.to_json()`\n",
        "* `df.to_dict()`\n",
        "\n",
        "There are also several other options available, but these are the most common.\n",
        "\n",
        "## Skipping and Limiting Rows\n",
        "\n",
        "Another feature that you may have to employ is skipping rows when there is metadata stored at the top of a file. You can do this using the optional parameter `skiprows`. Similarly, if you want to only load a portion of a large file as an initial preview, you can use the `nrows` parameter."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-bL_xIrqyiMg"
      },
      "outputs": [],
      "source": [
        "# Import the first 100 rows of 'ACS_16_5YR_B24011_with_ann.csv' file\n",
        "df = pd.read_csv('Data/ACS_16_5YR_B24011_with_ann.csv', nrows=100)\n",
        "\n",
        "# Look at the first five rows\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e6sqZMplyiMh"
      },
      "source": [
        "### Notice the first row is descriptions of the variables"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OOuy3DoKyiMh"
      },
      "source": [
        "We could manually remove:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mvgSEhvMyiMh"
      },
      "outputs": [],
      "source": [
        "# Delete the first row\n",
        "df = df.drop(0)\n",
        "df.head(2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-sD66sdNyiMi"
      },
      "source": [
        "Or if we knew from the start, we could use the skiprows argument:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "99CqdZTqyiMj"
      },
      "outputs": [],
      "source": [
        "# Import the first 100 rows of 'ACS_16_5YR_B24011_with_ann.csv' file while skipping the first row\n",
        "df = pd.read_csv('Data/ACS_16_5YR_B24011_with_ann.csv', skiprows=1, nrows=100)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w1jXK6gUyiMj"
      },
      "source": [
        "## Header\n",
        "\n",
        "Related to `skiprows` is the `header` parameter. This specifies the row where column names are and starts importing data from that point:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u-JqsFONyiMk"
      },
      "outputs": [],
      "source": [
        "# Look at the error output once you run this cell. What type of error is it?\n",
        "df = pd.read_csv('Data/ACS_16_5YR_B24011_with_ann.csv', header=1)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qPjVdYEXyiMl"
      },
      "source": [
        "## Encoding\n",
        "\n",
        "Encoding errors like the one above are always frustrating. This has to do with how the strings within the file itself are formatted. The most common encoding other than `utf-8` that you are likely to come across is `latin-1`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6rEOPO8eyiMl"
      },
      "outputs": [],
      "source": [
        "# Import the 'ACS_16_5YR_B24011_with_ann.csv' file using a proper encoding\n",
        "df = pd.read_csv('Data/ACS_16_5YR_B24011_with_ann.csv', header=1, encoding='latin-1')\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SxpobyGiyiMm"
      },
      "source": [
        "## Selecting Specific Columns  \n",
        "\n",
        "You can also select specific columns if you only want to load specific features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V5JllF56yiMn"
      },
      "outputs": [],
      "source": [
        "# Import the file with specific columns\n",
        "df = pd.read_csv('Data/ACS_16_5YR_B24011_with_ann.csv',\n",
        "                 usecols=[0, 1, 2, 5, 6], encoding='latin-1')\n",
        "df.head(2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kbe5uL9uyiMs"
      },
      "source": [
        "**or**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pdkJ1X52yiMt"
      },
      "outputs": [],
      "source": [
        "# Import the file with specific columns\n",
        "df = pd.read_csv('Data/ACS_16_5YR_B24011_with_ann.csv', usecols=['GEO.id', 'GEO.id2'], encoding='latin-1')\n",
        "df.head(2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "_WQ_3Vg7yiMt"
      },
      "source": [
        "## Selecting Specific Sheets\n",
        "You can also select specific sheets for Excel files. This can be done by index number."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iX5cZjTcyiMt"
      },
      "outputs": [],
      "source": [
        "# Import an Excel file\n",
        "df1 = pd.read_excel('Data/Yelp_Selected_Businesses.xlsx', header=2)\n",
        "df1.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w5vLlK5iyiMu"
      },
      "outputs": [],
      "source": [
        "# Import a specific sheet of an Excel file\n",
        "df2 = pd.read_excel('Data/Yelp_Selected_Businesses.xlsx', sheet_name=2, header=2)\n",
        "df2.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5xvS-tHoyiMu"
      },
      "source": [
        "Or the name of the sheet itself"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Owt9o4NGyiMu"
      },
      "outputs": [],
      "source": [
        "# Import a specific sheet of an Excel file\n",
        "df = pd.read_excel('Data/Yelp_Selected_Businesses.xlsx', sheet_name='Biz_id_RESDU', header=2)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Ns1-f-3yiMu"
      },
      "source": [
        "## Loading a Full Workbook and Previewing Sheet Names\n",
        "You can also load an entire excel workbook (which is a collection of spreadsheets) with the `pd.ExcelFile()` function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ob4P6rtOyiMu"
      },
      "outputs": [],
      "source": [
        "# Import the names of Excel sheets in a workbook\n",
        "workbook = pd.ExcelFile('Data/Yelp_Selected_Businesses.xlsx')\n",
        "workbook.sheet_names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RvYHxR8EyiMv"
      },
      "outputs": [],
      "source": [
        "# Import a specific sheet\n",
        "df = workbook.parse(sheet_name=1, header=2)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FZgIUNUTyiMv"
      },
      "source": [
        "## Saving Data\n",
        "Once we have data loaded that we may want to export back out, we use the **`.to_csv()`** or **`.to_excel()`** methods of any DataFrame object."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MmYwGzwtyiMv"
      },
      "outputs": [],
      "source": [
        "# Write data to a CSV file\n",
        "# Notice how we have to pass index=False if we do not want it included in our output\n",
        "df.to_csv('NewSavedView.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g0zCNAktyiMv"
      },
      "outputs": [],
      "source": [
        "# Write data to an Excel file\n",
        "df.to_excel('NewSavedView.xlsx')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "zJvR4X3pyiMw"
      },
      "source": [
        "## Summary\n",
        "\n",
        "We've spent some time looking into how data importing with Pandas works and some of the methods you can use to manage the import and access of data."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python (learn-env)",
      "language": "python",
      "name": "learn-env"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}